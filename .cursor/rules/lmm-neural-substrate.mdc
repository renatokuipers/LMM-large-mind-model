---
description: Guidelines for implementing the foundational neural architecture that underpins all cognitive modules.
globs: lmm_project/neural_substrate/*.py
alwaysApply: true
---
# LMM Neural Substrate Guidelines

The neural substrate provides the primitive neural building blocks from which higher cognitive functions will emerge. This is the foundation of the entire system and must be implemented with care.

## Key Neural Components

- **Neurons**: Basic processing units with activation functions
- **Synapses**: Connections between neurons with modifiable weights
- **Neural Clusters**: Functional groupings of neurons
- **Hebbian Learning**: "Neurons that fire together, wire together" learning mechanism
- **Activation Functions**: Non-linear transformations of neural inputs

## Implementation Requirements

- Implement basic neurons with configurable activation functions
- Create synapses with modifiable connection strengths
- Support both excitatory and inhibitory connections
- Implement Hebbian learning to strengthen connections based on correlated activity
- Support neural clustering for functional organization
- Ensure all neural components are serializable for state persistence
- Use PyTorch for underlying tensor operations when applicable
- Implement efficient CUDA-compatible code paths

## Neural Network Structure

- Start with simple feedforward networks with minimal structure
- Allow for dynamic network growth and modification during development
- Support both plastic (easily modified) and stable (relatively fixed) components
- Implement neural pruning to remove unused connections
- Support modularity where specialized neural circuits develop for specific functions

## Learning Implementation

- Focus on unsupervised and self-supervised learning mechanisms
- Implement various forms of Hebbian learning (basic, competitive, STDP)
- Support homeostatic plasticity to prevent runaway activation
- Implement neural consolidation for stabilizing important connections
- Ensure learning rates can be modulated based on developmental stage

## GPU Acceleration

- Use CUDA 12.1 for neural processing where appropriate
- Implement fallback CPU paths for all operations
- Use torch.cuda.is_available() to detect GPU capability
- Always initialize CUDA tensors on the correct device
- Optimize memory usage for GPU operations